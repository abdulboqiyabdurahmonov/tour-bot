# -*- coding: utf-8 -*-
"""
collector.py ‚Äî —É–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å —Ç–æ—á–Ω—ã–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º –æ—Ç–µ–ª–µ–π/—Ü–µ–Ω/–¥–∞—Ç –∏–∑ ¬´—Å–≤–∞–ª–æ—á–Ω–æ–≥–æ¬ª —Ç–µ–∫—Å—Ç–∞.

–ì–ª–∞–≤–Ω–æ–µ:
- –ñ—ë—Å—Ç–∫–∏–π –∞–Ω—Ç–∏-—à—É–º –ø–æ –≥–µ–æ: –Ω–µ –ø—É—Ç–∞–µ–º –æ—Å—Ç—Ä–æ–≤/–≥–æ—Ä–æ–¥/—Ä–µ–≥–∏–æ–Ω —Å –æ—Ç–µ–ª–µ–º.
- N‚Äëgram –ø–æ –∑–∞–≥–ª–∞–≤–Ω—ã–º —Å–ª–æ–≤–∞–º + —Å—É—Ñ—Ñ–∏–∫—Å—ã-¬´–º–∞—Ä–∫–µ—Ä—ã –æ—Ç–µ–ª–µ–π¬ª + –±—Ä–µ–Ω–¥‚Äë—Ö–∏–Ω—Ç—ã.
- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Å–ø–∏—Å–∫–æ–≤: "Rixos Premium, Titanic Deluxe, Concorde ..." ‚Üí –Ω–µ—Å–∫–æ–ª—å–∫–æ –æ—Ç–µ–ª–µ–π.
- –°—Ç—Ä–æ–≥–∏–π –ø–∞—Ä—Å–∏–Ω–≥ –¥–∞—Ç –¥–ª—è RU/UZ (–∫–∏—Ä–∏–ª–ª–∏—Ü–∞/–ª–∞—Ç–∏–Ω–∏—Ü–∞) –∏ —Ñ–æ—Ä–º–∞—Ç–æ–≤ ("12‚Äì19 —Å–µ–Ω—Ç", "12.09‚Äì19.09", "—Å 12 –ø–æ 19 —Å–µ–Ω—Ç").
- –ê–∫–∫—É—Ä–∞—Ç–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ü–µ–Ω—ã/–≤–∞–ª—é—Ç—ã, –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤–∞–ª—é—Ç.
- –ë–∞—Ç—á‚Äë–∞–ø—Å–µ—Ä—Ç—ã –∏ —Ñ–∏–ª—å—Ç—Ä—ã –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã.

–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –±–æ—Ç –Ω–µ —Ç—Ä–µ–±—É–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–π –ë–î (—Å—Ö–µ–º–∞ –∏–∑ db_init.py –ø–æ–¥—Ö–æ–¥–∏—Ç).
"""

from __future__ import annotations
import os
import re
import logging
import asyncio
from datetime import datetime, timedelta, timezone
from typing import List, Optional, Tuple

from telethon.sessions import StringSession
from telethon import TelegramClient
from psycopg import connect

# >>> SAN: imports
from utils.sanitazer import (
    San, TourDraft, build_tour_key,
    safe_run, RetryPolicy
)
# <<< SAN: imports

# ============ –õ–û–ì–ò ============
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

# ============ ENV ============
API_ID = int(os.getenv("TG_API_ID"))
API_HASH = os.getenv("TG_API_HASH")
SESSION_B64 = os.getenv("TG_SESSION_B64")
CHANNELS = [c.strip() for c in os.getenv("CHANNELS", "").split(",") if c.strip()]  # –ø—Ä–∏–º–µ—Ä: @tour1,@tour2
DATABASE_URL = os.getenv("DATABASE_URL")

# >>> SAN: –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏ / –Ω–∞–≥—Ä—É–∑–∫–∏
FETCH_LIMIT = int(os.getenv("FETCH_LIMIT", "80"))                 # —Å–∫–æ–ª—å–∫–æ —Å–æ–æ–±—â–µ–Ω–∏–π –Ω–∞ –∫–∞–Ω–∞–ª –∑–∞ –ø—Ä–æ—Ö–æ–¥
MAX_POST_AGE_DAYS = int(os.getenv("MAX_POST_AGE_DAYS", "45"))     # –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–æ—Å—Ç—ã —Å—Ç–∞—Ä—à–µ N –¥–Ω–µ–π
REQUIRE_PRICE = os.getenv("REQUIRE_PRICE", "1") == "1"            # –µ—Å–ª–∏ True ‚Äî –±–µ–∑ —Ü–µ–Ω—ã –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
BATCH_SIZE = int(os.getenv("BATCH_SIZE", "30"))                   # —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è upsert
SLEEP_BASE = int(os.getenv("SLEEP_BASE_SEC", "900"))              # –±–∞–∑–æ–≤—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É –ø—Ä–æ—Ö–æ–¥–∞–º–∏
# <<< SAN: –Ω–∞—Å—Ç—Ä–æ–π–∫–∏

if not API_ID or not API_HASH or not SESSION_B64 or not CHANNELS:
    raise ValueError("‚ùå –ü—Ä–æ–≤–µ—Ä—å TG_API_ID, TG_API_HASH, TG_SESSION_B64 –∏ CHANNELS –≤ .env")

# ============ –ë–î ============
def get_conn():
    return connect(DATABASE_URL, autocommit=True)

# >>> SAN: UPSERT (named params) + bulk
SQL_UPSERT_TOUR = """
INSERT INTO tours(
    country, city, hotel, price, currency, dates, description,
    source_url, posted_at, message_id, source_chat, stable_key
)
VALUES (%(country)s, %(city)s, %(hotel)s, %(price)s, %(currency)s, %(dates)s, %(description)s,
        %(source_url)s, %(posted_at)s, %(message_id)s, %(source_chat)s, %(stable_key)s)
ON CONFLICT (message_id, source_chat) DO UPDATE SET
    country     = EXCLUDED.country,
    city        = EXCLUDED.city,
    hotel       = EXCLUDED.hotel,
    price       = EXCLUDED.price,
    currency    = EXCLUDED.currency,
    dates       = EXCLUDED.dates,
    description = EXCLUDED.description,
    source_url  = EXCLUDED.source_url,
    posted_at   = EXCLUDED.posted_at,
    stable_key  = EXCLUDED.stable_key;
"""

def save_tours_bulk(rows: list[dict]):
    """–ë–∞—Ç—á-–∞–ø—Å–µ—Ä—Ç—ã: –±—ã—Å—Ç—Ä–µ–µ –∏ —É—Å—Ç–æ–π—á–∏–≤–µ–µ –ø–æ–¥ –Ω–∞–≥—Ä—É–∑–∫–æ–π."""
    if not rows:
        return
    try:
        with get_conn() as conn, conn.cursor() as cur:
            cur.executemany(SQL_UPSERT_TOUR, rows)
        logging.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–∏–ª/–æ–±–Ω–æ–≤–∏–ª –±–∞—Ç—á: {len(rows)} —à—Ç.")
    except Exception as e:
        # –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π fallback –ø–æ –æ–¥–Ω–æ–º—É ‚Äî —á—Ç–æ–±—ã –Ω–µ –ø–æ—Ç–µ—Ä—è—Ç—å –≤—Å—ë –∏–∑-–∑–∞ –æ–¥–Ω–æ–≥–æ –∫—Ä–∏–≤–æ–≥–æ –ø–æ—Å—Ç–∞
        logging.warning(f"‚ö†Ô∏è Bulk upsert failed, fallback to single. Reason: {e}")
        for r in rows:
            try:
                with get_conn() as conn, conn.cursor() as cur:
                    cur.execute(SQL_UPSERT_TOUR, r)
            except Exception as ee:
                logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ç—É—Ä–∞ (msg={r.get('message_id')}): {ee}")
# <<< SAN: UPSERT


# ============ –°–õ–û–í–ê–†–ò/–†–ï–ì–ï–ö–°–´ –î–õ–Ø –¢–û–ß–ù–û–ì–û –ò–ó–í–õ–ï–ß–ï–ù–ò–Ø ============
# –°—É—Ñ—Ñ–∏–∫—Å—ã/–º–∞—Ä–∫–µ—Ä—ã –æ—Ç–µ–ª—å–Ω—ã—Ö –Ω–∞–∑–≤–∞–Ω–∏–π (ru/uz/en)
WHITELIST_SUFFIXES = [
    # EN
    " hotel", " resort", " inn", " lodge", " suites", " villa", " villas", " bungalow", " bungalows",
    " palace", " spa", " beach", " residence", " residences", " apartments", " apart", " apart-hotel", " aparthotel",
    " guesthouse", " boutique", " camp", " deluxe", " premium",
    # RU
    " –æ—Ç–µ–ª—å", " –≥–æ—Å—Ç–∏–Ω–∏—Ü–∞", " —Å–∞–Ω–∞—Ç–æ—Ä–∏–π", " –ø–∞–Ω—Å–∏–æ–Ω–∞—Ç", " –≤–∏–ª–ª–∞", " —Ä–µ–∑–∏–¥–µ–Ω—Å", " —Ä–µ–∑–æ—Ä—Ç",
    # UZ/TR
    " mehmonxona", " otel", " oteli",
]

# –ë—Ä–µ–Ω–¥—ã/—Ü–µ–ø–æ—á–∫–∏ ‚Äî —É—Å–∏–ª–∏–≤–∞—é—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
BRAND_HINTS = [
    "rixos", "titanic", "voyage", "miracle", "concorde", "arcanus", "adam & eve", "maxx royal",
    "barut", "limak", "granada", "akra", "cornelia", "gloria", "susesi",
    "delphin", "alva donna", "paloma", "ic hotels", "kaya", "swandor", "regnum", "seginus",
    "hilton", "marriott", "sheraton", "radisson", "novotel", "mercure", "fairmont", "four seasons",
]

# –¢–æ–∫–µ–Ω—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –¥–æ–ª–∂–Ω—ã —Ç—Ä–∞–∫—Ç–æ–≤–∞—Ç—å—Å—è –∫–∞–∫ –æ—Ç–µ–ª–∏ (–≥–µ–æ/–≥–æ—Ä–æ–¥–∞/—Å—Ç—Ä–∞–Ω—ã/–æ–±—â–∏–µ —Å–ª–æ–≤–∞)
BLACKLIST_TOKENS = [
    # –ì–µ–æ-–æ–±—â–µ–µ
    "island", "atoll", "archipelago", "peninsula", "bay", "gulf", "lagoon",
    # RU/UZ –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ –≥–µ–æ
    "–æ—Å—Ç—Ä–æ–≤", "–∞—Ç–æ–ª–ª", "–∑–∞–ª–∏–≤", "–ª–∞–≥—É–Ω–∞", "–ø–æ–ª—É–æ—Å—Ç—Ä–æ–≤", "–∫—É—Ä–æ—Ä—Ç", "–ø–ª—è–∂", "–ø–æ–±–µ—Ä–µ–∂—å–µ",
    "—Ç—É—Ä—Ü–∏—è", "–µ–≥–∏–ø–µ—Ç", "–æ–∞—ç", "–æ–∞–µ", "—Ç–∞–∏–ª–∞–Ω–¥", "—É–∑–±–µ–∫–∏—Å—Ç–∞–Ω", "–º–∞–ª–¥–∏–≤—ã", "–º–∞–ª–¥–∏–≤", "—á–µ—Ä–Ω–æ–≥–æ—Ä–∏—è",
    "–∞–Ω—Ç–∞–ª–∏—è", "–∞–ª–∞–Ω–∏—è", "–±–æ–¥—Ä—É–º", "–∫–µ–º–µ—Ä", "—Å–∏–¥–µ", "–±–µ–ª–µ–∫", "—à–∞—Ä–º", "—Ö—É—Ä–≥–∞–¥–∞", "–¥–∞—Ö–∞–∞–±", "–º–∞—Ä—Å–∞ –∞–ª–∞–º",
    # EN –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ –æ—Å—Ç—Ä–æ–≤–∞/–∫—É—Ä–æ—Ä—Ç—ã
    "bali", "phuket", "samui", "lombok", "zanzibar", "goa", "antalya", "alanya", "kemer", "bodrum",
    # –û–±—â–∏–µ
    "—Ü–µ–Ω—Ç—Ä", "–ø–∞—Ä–∫", "–∞—ç—Ä–æ–ø–æ—Ä—Ç", "—Ä—ã–Ω–æ–∫", "–º–æ–ª–ª", "–Ω–∞–±–µ—Ä–µ–∂–Ω–∞—è", "downtown", "airport",
]

# –ù–µ–±–æ–ª—å—à–æ–π —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫ ¬´–æ–ø–∞—Å–Ω—ã—Ö¬ª –æ–¥–Ω–æ—Å–ª–æ–≤–Ω—ã—Ö –≥–µ–æ ‚Äî –≤—ã–∫–ª—é—á–∞–µ–º –∫–∞–∫ –æ–¥–∏–Ω–æ—á–Ω—ã–µ –æ—Ç–µ–ª–∏
KNOWN_GAZETTEER = {
    "bali", "phuket", "samui", "zanzibar", "goa", "antalya", "alanya", "kemer", "side", "belek",
    "dubai", "sharm", "hurghada", "dahab", "bodrum", "istanbul", "izmir", "batumi",
    "tashkent", "samarkand", "bukhara",
}

# –ü–∞—Ç—Ç–µ—Ä–Ω—ã
PRICE_RE = re.compile(r"(?P<cur>\$|usd|eur|‚Ç¨|—Å–æ–º|—Å—É–º|uzs|—Ä—É–±|‚ÇΩ|aed|ÿØ\.ÿ•)\s*(?P<amt>[\d\s.,]{2,})|(?P<amt2>[\d\s.,]{2,})\s*(?P<cur2>\$|usd|eur|‚Ç¨|—Å–æ–º|—Å—É–º|uzs|—Ä—É–±|‚ÇΩ|aed)", re.I)
NIGHTS_RE = re.compile(r"(?P<n>\d{1,2})\s*(–Ω–æ—á[–µ–∏]|ni[gh]hts?|kun|gece|gecesi)", re.I)
BOARD_RE = re.compile(r"\b(ai|uai|all\s*inclusive|bb|hb|fb|ro|ob|ultra\s*all)\b", re.I)
DATE_RE = re.compile(r"(\b\d{1,2}[./-]\d{1,2}(?:[./-]\d{2,4})?\b|\b\d{1,2}\s*(—è–Ω–≤|—Ñ–µ–≤|–º–∞—Ä|–∞–ø—Ä|–º–∞–π|–∏—é–Ω|–∏—é–ª|–∞–≤–≥|—Å–µ–Ω|–æ–∫—Ç|–Ω–æ—è|–¥–µ–∫)\w*\b)", re.I)
SPLIT_RE = re.compile(r"[,/\n‚Ä¢;|]\s*")

# ============ –î–ê–¢–´ (RU/UZ) ============
MONTHS_MAP = {
    # RU –∫—Ä–∞—Ç–∫–∏–µ
    "—è–Ω–≤": "01", "—Ñ–µ–≤": "02", "–º–∞—Ä": "03", "–∞–ø—Ä": "04", "–º–∞–π": "05", "–º–∞—è": "05",
    "–∏—é–Ω": "06", "–∏—é–ª": "07", "–∞–≤–≥": "08", "—Å–µ–Ω": "09", "—Å–µ–Ω—Ç": "09", "–æ–∫—Ç": "10", "–Ω–æ—è": "11", "–¥–µ–∫": "12",
    # RU –ø–æ–ª–Ω—ã–µ/–ø–∞–¥–µ–∂–∏
    "—è–Ω–≤–∞—Ä": "01", "—Ñ–µ–≤—Ä–∞–ª": "02", "–º–∞—Ä—Ç": "03", "–∞–ø—Ä–µ–ª": "04", "–∏—é–Ω—å": "06", "–∏—é–ª—å": "07",
    "–∞–≤–≥—É—Å—Ç": "08", "—Å–µ–Ω—Ç—è–±—Ä": "09", "–æ–∫—Ç—è–±—Ä": "10", "–Ω–æ—è–±—Ä": "11", "–¥–µ–∫–∞–±—Ä": "12",
    "—Å–µ–Ω—Ç—è–±—Ä—è": "09", "–æ–∫—Ç—è–±—Ä—è": "10", "–Ω–æ—è–±—Ä—è": "11", "–¥–µ–∫–∞–±—Ä—è": "12",
    # UZ –∫–∏—Ä–∏–ª–ª–∏—Ü–∞
    "—è–Ω–≤–∞—Ä": "01", "—Ñ–µ–≤—Ä–∞–ª": "02", "–º–∞—Ä—Ç": "03", "–∞–ø—Ä–µ–ª": "04", "–º–∞–π": "05", "–∏—é–Ω": "06", "–∏—é–ª": "07",
    "–∞–≤–≥—É—Å—Ç": "08", "—Å–µ–Ω—Ç—è–±—Ä": "09", "–æ–∫—Ç—è–±—Ä": "10", "–Ω–æ—è–±—Ä": "11", "–¥–µ–∫–∞–±—Ä": "12",
    # UZ –ª–∞—Ç–∏–Ω–∏—Ü–∞
    "yanv": "01", "fevral": "02", "mart": "03", "aprel": "04", "may": "05",
    "iyun": "06", "iyul": "07", "avgust": "08", "sentabr": "09", "sent": "09",
    "oktabr": "10", "noyabr": "11", "dekabr": "12",
}

def _norm_year(y: Optional[str]) -> int:
    if not y:
        return datetime.now().year
    y = int(y)
    if y < 100:
        y += 2000 if y < 70 else 1900
    return y


def _mk_date(d, m, y) -> str:
    return f"{int(d):02d}.{int(m):02d}.{_norm_year(y):04d}"


def _month_to_mm(token: Optional[str]) -> Optional[str]:
    if not token:
        return None
    t = token.strip().lower()
    for k, mm in MONTHS_MAP.items():
        if t.startswith(k):
            return mm
    return None


def parse_dates_strict(text: str) -> Optional[str]:
    """–ü–æ–¥–¥–µ—Ä–∂–∫–∞: "12‚Äì19 —Å–µ–Ω—Ç", "12.09‚Äì19.09", "—Å 12 –ø–æ 19 —Å–µ–Ω—Ç", –æ–¥–∏–Ω–æ—á–Ω—ã–µ –¥–∞—Ç—ã."""
    t = text.strip()
    m = re.search(r"(\d{1,2})[./-](\d{1,2})(?:[./-](\d{2,4}))?\s?[‚Äì\-]\s?(\d{1,2})[./-](\d{1,2})(?:[./-](\d{2,4}))?", t)
    if m:
        d1, m1, y1, d2, m2, y2 = m.groups()
        return f"{_mk_date(d1, m1, y1)}‚Äì{_mk_date(d2, m2, y2 or y1)}"

    m = re.search(r"(\d{1,2})\s?[‚Äì\-]\s?(\d{1,2})\s+([A-Za-z–ê-–Ø–∞-—è–Å—ë—û“ì“õ“≥]+)\w*", t, re.I)
    if m:
        d1, d2, mon = m.groups()
        mm = _month_to_mm(mon)
        if mm:
            y = datetime.now().year
            return f"{_mk_date(d1, mm, y)}‚Äì{_mk_date(d2, mm, y)}"

    m = re.search(r"(?:—Å|–±—É)\s?(\d{1,2})\s?(?:–ø–æ|—Ç–æ)\s?(\d{1,2})\s+([A-Za-z–ê-–Ø–∞-—è–Å—ë—û“ì“õ“≥]+)\w*", t, re.I)
    if m:
        d1, d2, mon = m.groups()
        mm = _month_to_mm(mon)
        if mm:
            y = datetime.now().year
            return f"{_mk_date(d1, mm, y)}‚Äì{_mk_date(d2, mm, y)}"

    m = re.search(r"\b(\d{1,2})[./-](\d{1,2})(?:[./-](\d{2,4}))?\b", t)
    if m:
        d, mth, y = m.groups()
        return _mk_date(d, mth, y)

    m = re.search(r"\b(\d{1,2})\s+([A-Za-z–ê-–Ø–∞-—è–Å—ë—û“ì“õ“≥]+)\w*", t)
    if m:
        d, mon = m.groups()
        mm = _month_to_mm(mon)
        if mm:
            y = datetime.now().year
            return _mk_date(d, mm, y)

    return None

# ============ –•–ï–õ–ü–ï–†–´ ============

def _amount_to_float(s: Optional[str]) -> Optional[float]:
    if not s:
        return None
    s = s.replace(' ', '').replace('\xa0', '')
    if s.count(',') == 1 and s.count('.') == 0:
        s = s.replace(',', '.')
    else:
        s = s.replace(',', '')
    try:
        return float(s)
    except Exception:
        return None


def _is_blacklisted(token: str) -> bool:
    t = token.lower()
    return t in KNOWN_GAZETTEER or any(t == b or t.endswith(b) or b in t for b in BLACKLIST_TOKENS)


def _score_hotel_candidate(text: str) -> float:
    """–°–∫–æ—Ä–∏–Ω–≥: –º–∞—Ä–∫–µ—Ä-—Å—É—Ñ—Ñ–∏–∫—Å, –±—Ä–µ–Ω–¥-—Ö–∏–Ω—Ç—ã, –∑–∞–≥–ª–∞–≤–Ω—ã–µ –±—É–∫–≤—ã, —à—Ç—Ä–∞—Ñ –∑–∞ blacklist."""
    t = text.lower()
    score = 0.0
    for suf in WHITELIST_SUFFIXES:
        if t.endswith(suf):
            score += 0.55
            break
    for bh in BRAND_HINTS:
        if bh in t:
            score += 0.25
            break
    if len(text) >= 4 and any(ch.isupper() for ch in text):
        score += 0.1
    toks = re.findall(r"[\w'-]+", t)
    if any(_is_blacklisted(tok) for tok in toks):
        score -= 0.6
    return max(0.0, min(1.0, score))


def _enum_ngrams(line: str, max_len: int = 5) -> List[str]:
    """N‚Äëgram –ø–æ –∑–∞–≥–ª–∞–≤–Ω—ã–º —Å–ª–æ–≤–∞–º: 'Rixos Premium Belek', 'Gloria Serenity Resort' –∏ —Ç.–ø."""
    tokens = re.findall(r"[\w'&.-]+", line)
    caps = [(tok, i) for i, tok in enumerate(tokens) if tok[:1].isupper() or tok.isupper()]
    spans = []
    for _, i in caps:
        for j in range(i + 1, min(i + 1 + max_len, len(tokens) + 1)):
            spans.append(" ".join(tokens[i:j]))
    return spans


def _split_candidates(raw: str) -> List[str]:
    parts = SPLIT_RE.split(raw)
    clean = [re.sub(r"\(.*?\)|\[.*?\]", "", p).strip() for p in parts]
    return [c for c in clean if c]


def strip_trailing_price_from_hotel(s: Optional[str]) -> Optional[str]:
    if not s:
        return s
    return re.sub(
        r'[\s‚Äì-]*(?:–æ—Ç\s*)?\d[\d\s.,]*\s*(?:USD|EUR|UZS|RUB|\$|‚Ç¨)\b.*$',
        '', s, flags=re.I
    ).strip()


def _extract_prices(text: str) -> Tuple[Optional[float], Optional[str]]:
    for m in PRICE_RE.finditer(text):
        g = m.groupdict()
        cur = g.get("cur") or g.get("cur2")
        amt = g.get("amt") or g.get("amt2")
        val = _amount_to_float(amt)
        if val:
            cu = (cur or '').upper()
            if cu in {"$", "US$", "USD$"}:
                cu = "USD"
            elif cu in {"‚Ç¨", "EUR‚Ç¨"}:
                cu = "EUR"
            elif cu in {"UZS", "–°–£–ú", "–°–£–ú–´", "–°–£–ú."}:
                cu = "UZS"
            elif cu in {"–†–£–ë", "–†–£–ë."}:
                cu = "RUB"
            return val, (cu or None)
    return None, None


def _extract_board(text: str) -> Optional[str]:
    m = BOARD_RE.search(text)
    return m.group(0).upper().replace(" ", "") if m else None


# ============ –ì–ï–û/–°–¢–†–ê–ù–ê ============
CITY2COUNTRY = {
    "–ù—è—á–∞–Ω–≥": "–í—å–µ—Ç–Ω–∞–º", "–ê–Ω—Ç–∞–ª—å—è": "–¢—É—Ä—Ü–∏—è", "–ü—Ö—É–∫–µ—Ç": "–¢–∞–∏–ª–∞–Ω–¥",
    "–ü–∞—Ç—Ç–∞–π—è": "–¢–∞–∏–ª–∞–Ω–¥", "–°–∞–º—É–∏": "–¢–∞–∏–ª–∞–Ω–¥", "–ö—Ä–∞–±–∏": "–¢–∞–∏–ª–∞–Ω–¥",
    "–ë–∞–Ω–≥–∫–æ–∫": "–¢–∞–∏–ª–∞–Ω–¥", "–î—É–±–∞–π": "–û–ê–≠", "–ë–∞–ª–∏": "–ò–Ω–¥–æ–Ω–µ–∑–∏—è",
    "–¢–±–∏–ª–∏—Å–∏": "–ì—Ä—É–∑–∏—è", "–®–∞—Ä–º": "–ï–≥–∏–ø–µ—Ç", "–•—É—Ä–≥–∞–¥–∞": "–ï–≥–∏–ø–µ—Ç",
}


def guess_country(city: Optional[str]) -> Optional[str]:
    if not city:
        return None
    return CITY2COUNTRY.get(city)


# ============ –ü–ê–†–°–ò–ù–ì –ü–û–°–¢–ê ============

def _extract_hotels(cleaned: str) -> List[str]:
    """–î–æ—Å—Ç–∞—ë–º —Å–ø–∏—Å–æ–∫ –≤–µ—Ä–æ—è—Ç–Ω—ã—Ö –æ—Ç–µ–ª–µ–π –∏–∑ –Ω–µ—Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.
    –ê–ª–≥–æ—Ä–∏—Ç–º: —Ä–µ–∂–µ–º –ø–æ —Å–ø–∏—Å–∫–æ–≤—ã–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º ‚Üí n‚Äëgram –ø–æ –∑–∞–≥–ª–∞–≤–Ω—ã–º ‚Üí —Å–∫–æ—Ä–∏–º ‚Üí —Ñ–∏–ª—å—Ç—Ä—É–µ–º.
    """
    hotels: List[str] = []
    for block in SPLIT_RE.split(cleaned):
        block = block.strip()
        if not block:
            continue
        ngrams = _enum_ngrams(block)
        candidates = []
        for span in ngrams:
            span_norm = strip_trailing_price_from_hotel(span)
            if not span_norm:
                continue
            score = _score_hotel_candidate(span_norm)
            if score >= 0.6:
                candidates.append((score, span_norm))
        candidates.sort(key=lambda x: (x[0], len(x[1])), reverse=True)
        if candidates:
            top = candidates[0][1]
            toks = re.findall(r"[\w'-]+", top.lower())
            if not any(tok in KNOWN_GAZETTEER for tok in toks):
                hotels.append(top)
    seen = set()
    uniq: List[str] = []
    for h in hotels:
        k = h.lower()
        if k not in seen:
            seen.add(k)
            uniq.append(h)
    return uniq[:5]


def parse_post(text: str, link: str, msg_id: int, chat: str, posted_at: "datetime"):
    """–†–∞–∑–±–æ—Ä –ø–æ—Å—Ç–∞ (–±–µ–∑ –∫–∞—Ä—Ç–∏–Ω–æ–∫), —É—Å—Ç–æ–π—á–∏–≤—ã–π –∫ –º—É—Å–æ—Ä—É –∏ —Ñ–æ—Ä–º–∞—Ç–∞–º."""
    raw = text or ""
    cleaned = San.clean_text(raw)
    draft = TourDraft.from_raw(cleaned)

    # –ì–æ—Ä–æ–¥ (—ç–≤—Ä–∏—Å—Ç–∏–∫–∞)
    city_match = re.search(r"(–ë–∞–ª–∏|–î—É–±–∞–π|–ù—è—á–∞–Ω–≥|–ê–Ω—Ç–∞–ª—å—è|–ü—Ö—É–∫–µ—Ç|–ü–∞—Ç—Ç–∞–π—è|–ö—Ä–∞–±–∏|–¢–±–∏–ª–∏—Å–∏|–®–∞—Ä–º|–•—É—Ä–≥–∞–¥–∞)", cleaned, re.I)
    city = city_match.group(1) if city_match else (draft.city if getattr(draft, 'city', None) else None)
    if not city:
        m = re.search(r"\b([–ê-–Ø–Å][–∞-—è—ë]+)\b", cleaned)
        city = m.group(1) if m else None

    # –û—Ç–µ–ª–∏ (–º—É–ª—å—Ç–∏-–∏–∑–≤–ª–µ—á–µ–Ω–∏–µ)
    hotels = _extract_hotels(cleaned)
    hotel = hotels[0] if hotels else (strip_trailing_price_from_hotel(draft.hotel) if draft.hotel else None)

    # –î–∞—Ç—ã: —Å—Ç—Ä–æ–≥–∏–π —Ä–∞–∑–±–æ—Ä RU/UZ
    dates = parse_dates_strict(cleaned) or draft.dates

    # –¶–µ–Ω–∞/–≤–∞–ª—é—Ç–∞: —Å–Ω–∞—á–∞–ª–∞ –∏–∑ draft, –∏–Ω–∞—á–µ fallback
    price, currency = draft.price, draft.currency
    if price is None or currency is None:
        price, currency = _extract_prices(cleaned)

    # –í–∞–ª—é—Ç–∞ ‚Äî –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è, –µ—Å–ª–∏ –ø—É—Å—Ç–∞—è, –ø—Ä–æ–±—É–µ–º –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É
    if currency:
        cu = str(currency).strip().upper()
        if cu in {"$", "US$", "USD$"}:
            currency = "USD"
        elif cu in {"‚Ç¨", "EUR‚Ç¨"}:
            currency = "EUR"
        elif cu in {"UZS", "–°–£–ú", "–°–£–ú–´", "–°–£–ú."}:
            currency = "UZS"
        elif cu in {"RUB", "–†–£–ë", "–†–£–ë."}:
            currency = "RUB"
        else:
            currency = cu
    else:
        low = cleaned.lower()
        if "—Å—É–º" in low or "uzs" in low:
            currency = "UZS"
        elif "eur" in low or "‚Ç¨" in low:
            currency = "EUR"
        elif "usd" in low or "$" in low:
            currency = "USD"

    # –°—Ç–∞–±–∏–ª—å–Ω—ã–π –∫–ª—é—á (—É—Ç–æ—á–Ω–∏–º –ø–æ–∑–∂–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –æ—Ç–µ–ª—è)
    payload_base = {
        "country": guess_country(city) if city else None,
        "city": city,
        "price": price,
        "currency": currency,
        "dates": dates,
        "description": cleaned[:500],
        "source_url": link,
        "posted_at": posted_at.replace(tzinfo=None),
        "message_id": msg_id,
        "source_chat": chat,
    }

    return payload_base, (hotels if hotels else [hotel] if hotel else [])


# ============ –ö–û–õ–õ–ï–ö–¢–û–† ============
async def collect_once(client: TelegramClient):
    """–û–¥–∏–Ω –ø—Ä–æ—Ö–æ–¥ –ø–æ –≤—Å–µ–º –∫–∞–Ω–∞–ª–∞–º —Å –±–∞—Ç—á-—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∏ —Ñ–∏–ª—å—Ç—Ä–∞–º–∏ –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏."""
    now = datetime.now(timezone.utc)
    cutoff = now - timedelta(days=MAX_POST_AGE_DAYS)

    for channel in CHANNELS:
        logging.info(f"üì• –ß–∏—Ç–∞—é –∫–∞–Ω–∞–ª: {channel}")
        batch: list[dict] = []

        async for msg in client.iter_messages(channel, limit=FETCH_LIMIT):
            if not msg.text:
                continue

            # –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Å–ª–∏—à–∫–æ–º —Å—Ç–∞—Ä—ã–µ –ø–æ—Å—Ç—ã
            if msg.date and msg.date.replace(tzinfo=None) < cutoff.replace(tzinfo=None):
                continue

            def _make_rows() -> List[dict]:
                base, hotels = parse_post(
                    msg.text,
                    f"https://t.me/{channel.strip('@')}/{msg.id}",
                    msg.id,
                    channel,
                    msg.date
                )
                rows: List[dict] = []
                for h in hotels:
                    if not h:
                        continue
                    row = {
                        **base,
                        "hotel": h,
                    }
                    row["stable_key"] = build_tour_key(
                        source_chat=base["source_chat"],
                        message_id=base["message_id"],
                        city=base.get("city") or "",
                        hotel=h,
                        price=(base.get("price"), base.get("currency")) if base.get("price") else None,
                    )
                    rows.append(row)
                if not rows and not REQUIRE_PRICE:
                    rows.append({**base, "hotel": None, "stable_key": build_tour_key(base["source_chat"], base["message_id"], base.get("city") or "", "", None)})
                return rows

            rows = _make_rows()
            if REQUIRE_PRICE:
                rows = [r for r in rows if (r.get("price") is not None and r.get("currency") is not None)]

            if rows:
                batch.extend(rows)

            # –±–∞—Ç—á-—Å–±—Ä–æ—Å
            if len(batch) >= BATCH_SIZE:
                await safe_run(lambda: asyncio.to_thread(save_tours_bulk, batch.copy()),
                               RetryPolicy(attempts=4, base_delay=0.25, max_delay=2.0))
                batch.clear()

        # –æ—Å—Ç–∞—Ç–∫–∏ –±–∞—Ç—á–∞ –ø–æ—Å–ª–µ –∫–∞–Ω–∞–ª–∞
        if batch:
            await safe_run(lambda: asyncio.to_thread(save_tours_bulk, batch.copy()),
                           RetryPolicy(attempts=4, base_delay=0.25, max_delay=2.0))
            batch.clear()

async def run_collector():
    client = TelegramClient(StringSession(SESSION_B64), API_ID, API_HASH)
    await client.start()
    logging.info("‚úÖ Collector –∑–∞–ø—É—â–µ–Ω")
    while True:
        try:
            await collect_once(client)
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –∫–æ–ª–ª–µ–∫—Ç–æ—Ä–µ: {e}")
        # –ª—ë–≥–∫–∏–π –¥–∂–∏—Ç—Ç–µ—Ä, —á—Ç–æ–±—ã –Ω–µ –ø–æ–ø–∞–¥–∞—Ç—å –≤ —Ä–æ–≤–Ω—ã–µ –º–∏–Ω—É—Ç—ã –∏ —Ä–∞–∑–æ–π—Ç–∏—Å—å —Å –¥—Ä—É–≥–∏–º–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞–º–∏
        await asyncio.sleep(SLEEP_BASE + int(10 * (os.getpid() % 3)))

if __name__ == "__main__":
    asyncio.run(run_collector())
